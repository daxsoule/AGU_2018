{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seafloor Bacterial Floc Analysis Using Regions Information\n",
    "\n",
    "This notebook shows an example of doing an analysis of water column \"floc\" using Pangeo and the regions data from Aaron's [CamHD_motion_metadata](https://github.com/CamHD-Analysis/CamHD_motion_metadata) repo. The goal of this work is to understand changes in the concentration of floc, which is bacterial material that has been flushed from the hydrothermal system into the ocean. Changes in floc are a potential indicator of changes in the hydrothermal system, possibly resulting from a magmatic event or seismic swarm.\n",
    " \n",
    " \n",
    "In this notebook we analyze a large number of OOI HD video camera frames to establish a proxy for the floc concentration, and then display the results using a two-dimensional multivariate histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a list of CamHD files to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pycamhd as camhd\n",
    "import numpy as np\n",
    "from dask import delayed\n",
    "import dask.array as dsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = []\n",
    "filename = []\n",
    "scene_tag = []\n",
    "deployment = []\n",
    "start_framed = []\n",
    "end_framed = []\n",
    "\n",
    "with open('region.txt') as f:\n",
    "    for line in f:\n",
    "        with open(line.strip()) as l:\n",
    "            data = json.load(l)\n",
    "            for region in data['regions']:\n",
    "                if region['type'] == 'static':\n",
    "                    try:\n",
    "                        if '_p2_z0' in region['sceneTag']:\n",
    "                            url.append('https://rawdata.oceanobservatories.org/files' + data['movie']['URL'])\n",
    "                            filename.append((data['movie']['URL'].split('/')[-1]))\n",
    "                            scene_tag.append(region['sceneTag'])\n",
    "                            deployment.append(int(scene_tag[-1].split('_')[0][1]))                            \n",
    "                            start_framed.append(int(region['startFrame']))\n",
    "                            end_framed.append(int(region['endFrame']))\n",
    "                    except:\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Whom It May Concern: \n",
    "#### Here is a cell that starts by defining a proper buffer for our start and end frames. The idea being that the buffer will provent us from pulling frames that may include the end or beggining of the CamHD's movement.\n",
    "#### We go on to create a dataframe of relevent information from a list of movies that fit specifications made in the cell above\n",
    "#### From here we apply a function to the rows of the dataframe that takes the defined frame_interval for the range give by the start_frame to end_frame \n",
    "#### We then add that the list of frames as a column 'window' to our data\n",
    "#### We then go through our dataframe and filter it to display only the rows from the given deployment (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_buffer = 10\n",
    "frame_interval = 30\n",
    "start_frame = [x+frame_buffer for x in start_framed]\n",
    "end_frame = [x-frame_buffer for x in end_framed]\n",
    "scene_windows = pd.DataFrame({'filename': filename, 'url': url, 'scene_tag': scene_tag, 'deployment': deployment, 'start_frame': start_frame, 'end_frame': end_frame})\n",
    "def window(row):\n",
    "    return range(row.start_frame, row.end_frame, frame_interval)\n",
    "\n",
    "scene_windows['window'] = scene_windows.apply(window, axis=1)\n",
    "scene_windows.loc[(scene_windows.deployment == 5)]\n",
    "\n",
    "scene_windows.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# delayed_frame_list = []\n",
    "# for i, filename in enumerate(scene_windows):\n",
    "#     delayed_moov_atom = delayed(camhd.get_moov_atom)(url)\n",
    "#     delayed_frame = delayed(camhd.get_frame)(filename, frame_numbers[i], 'gray16le', delayed_moov_atom)\n",
    "#     for i, start_frame in enumerate(scene_windows.start_frame):\n",
    "#         i == 1\n",
    "#         print(delayed_frame_list)\n",
    "#         break\n",
    "delayed_frame_list = []\n",
    "for i, filename in enumerate(scene_windows):\n",
    "    delayed_moov_atom = delayed(camhd.get_moov_atom)(url)\n",
    "    delayed_frame = delayed(camhd.get_frame)(url, window, 'gray16le', delayed_moov_atom)\n",
    "    delayed_frame_list.append(dsa.from_delayed(delayed_frame, (1080, 1920), np.uint16))\n",
    "    i == 1\n",
    "    print(delayed_frame_list)\n",
    "    break\n",
    "   \n",
    "# delayed_frame_array = dsa.stack(delayed_frame_list)\n",
    "# delayed_frame_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_frame_list = []\n",
    "for i, filename in enumerate(scene_windows):\n",
    "    delayed_file = filename\n",
    "    delayed_frame_list.append(delayed_file)\n",
    "    delayed_frame = window\n",
    "    delayed_frame_list.append(delayed_frame)\n",
    "    i == 1\n",
    "    print(delayed_frame_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the frame numbers from each file to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(delayed_frame_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval = 30\n",
    "# padding = 10\n",
    "# # frame_windows = []\n",
    "# d = {'start': scene_windows.start_frame+padding, 'end': scene_windows.end_frame-padding,'filenames': scene_windows.filename}\n",
    "# # end = scene_windows.end_frame-padding\n",
    "# # range(start, end, interval)\n",
    "# frame_windows = pd.DataFrame(index=None, columns= ['start', 'end', 'filenames'], data=d, dtype=None, copy=False)\n",
    "\n",
    "# # # frame_windows.append(window)\n",
    "# def window(row):\n",
    "#     return range(row.start, row.end, 30)\n",
    "\n",
    "# frame_windows['window'] = frame_windows.apply(window, axis=1)\n",
    "\n",
    "# # # DataFrame.append(other, ignore_index=False, verify_integrity=False, sort=None)\n",
    "# # # frame_windows.append(list(start_frame+padding, scene_windows.end_frame-padding, interval))\n",
    "# # # # frame_numbers.append(list(range(start_frame+padding, scene_windows.end_frame[i]-padding, interval)))\n",
    "\n",
    "# # #     if i == 1:\n",
    "# # #         break\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# frame_windows.append(list(start_frame+padding, scene_windows.end_frame-padding, interval))\n",
    "# # frame_numbers.append(list(range(start_frame+padding, scene_windows.end_frame[i]-padding, interval)))\n",
    "\n",
    "#     if i == 1:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for [first iterating variable] in [outer loop]: # Outer loop\n",
    "#     [do something]  # Optional\n",
    "#     for [second iterating variable] in [nested loop]:   # Nested loop\n",
    "#         [do something]  \n",
    "        \n",
    "# delayed_frame_list = []\n",
    "# for i, filename in enumerate(filenames):\n",
    "#     delayed_file = filename\n",
    "#     delayed_frame_list.append(delayed_file)\n",
    "#     for j, frame_number in enumerate(frame_numbers):\n",
    "#         delayed_frame = frame_number\n",
    "#         delayed_frame_list.append(delayed_frame)\n",
    "# delayed_file_info = []\n",
    "\n",
    "# for i, filename in filename.index:\n",
    "#     delayed_file = filename[i]\n",
    "#     delayed_frame_list.append(delayed_file)\n",
    "#     for i in frame_number.index:\n",
    "#         delayed_frame = frame_number\n",
    "#         delayed_frame_list.append(delayed_frame)\n",
    "# delayed_frame_list\n",
    "# delayed_file_info = []\n",
    "delayed_frame_list = []\n",
    "for i, filename in enumerate(filenames):\n",
    "    delayed_file = filename\n",
    "    delayed_frame_list.append(delayed_file)\n",
    "    delayed_frame = frame_numbers[i]\n",
    "    delayed_frame_list.append(delayed_frame)\n",
    "    #for i, delayed_file in enumerate(delayed_frame_list):\n",
    "     #   delayed_frame = frame_numbers[i]\n",
    "      #  delayed_frame_list.append(delayed_frame)\n",
    "#         i == (9)\n",
    "#     break\n",
    "#         print(delayed_frame_list)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.python.org/3.3/library/functions.html#zip\n",
    "Make an iterator that aggregates elements from each of the iterables.\n",
    "\n",
    "Returns an iterator of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables. \n",
    "The iterator stops when the shortest input iterable is exhausted. With a single iterable argument, it returns an iterator of 1-tuples. \n",
    "With no arguments, it returns an empty iterator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These frame numbers correspond to times when the camera system is looking over the \"shoulder\" of Mushroom vent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a delayed Dask array of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycamhd as camhd\n",
    "import numpy as np\n",
    "from dask import delayed\n",
    "import dask.array as dsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_frame_list = []\n",
    "for i, filename in enumerate(filenames):\n",
    "    delayed_moov_atom = delayed(camhd.get_moov_atom)(filename)\n",
    "    delayed_frame = delayed(camhd.get_frame)(filename, frame_numbers, 'gray16le', delayed_moov_atom)\n",
    "    delayed_frame_list.append(dsa.from_delayed(delayed_frame, (1080, 1920), np.uint16))\n",
    "   \n",
    "delayed_frame_array = dsa.stack(delayed_frame_list)\n",
    "delayed_frame_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "delayed_frame_list = []\n",
    "for i, filename in enumerate(filenames):\n",
    "    delayed_moov_atom = delayed(camhd.get_moov_atom)(filename)\n",
    "    delayed_frame = delayed(camhd.get_frame)(filename, frame_numbers[i], 'gray16le', delayed_moov_atom)\n",
    "    for i, start_frame in enumerate(scene_windows.start_frame):\n",
    "        i == 1\n",
    "        print(delayed_frame_list)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(delayed_frame_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(delayed_moov_atom.dask.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"doody.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dask array is in many ways like a numpy array, except in this case it holds a set of instructions for how to acquire each chunk of the array, which makes it easy to farm this array out to workers in the cloud using the [distributed](http://distributed.readthedocs.io/en/latest/#) scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show one of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = delayed_frame_array[0].compute()\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "plt.rc('figure', figsize=(11, 11))\n",
    "fig, ax = plt.subplots()\n",
    "im1 = ax.imshow(frame)\n",
    "im1.set_cmap('gray')\n",
    "plt.yticks(np.arange(0,1081,270))\n",
    "plt.xticks(np.arange(0,1921,480))\n",
    "rect = patches.Rectangle((10,10),1024,1024,linewidth=1.5,edgecolor='w',facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the filter that will be used to filter images in the frequency domain\n",
    "To deal with variations in lighting and high-frequency noise, we filter each subimage using a Butterworth bandpass filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butterworth(d1, d2, n):\n",
    "    x = np.arange(-1024/2+0.5,1024/2+1-0.5)\n",
    "    xx, yy = np.meshgrid(x, x)\n",
    "    d = np.sqrt(xx**2+yy**2)\n",
    "    bff = (1 - (1./(1 + (d/d1)**(2*n))))*(1/(1 + (d/d2)**(2*n)))\n",
    "    return bff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = 20 # low cut wavenumber\n",
    "d2 = 400 # high cut wavenumber\n",
    "n = 4\n",
    "bff = butterworth(d1, d2, n)\n",
    "plt.rc('figure', figsize=(6, 6))\n",
    "imgplot = plt.imshow(bff, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the floc proxy function\n",
    "The floc proxy is simply the number of pixels in each filtered subimage that have a value greater than 4000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_filter(frame, d1, d2, n):\n",
    "    if frame.ndim == 3 and frame.shape[0] == 1:\n",
    "        I = np.squeeze(frame[0, 0:1024, 0:1024])\n",
    "    else:\n",
    "        I = frame[0:1024, 0:1024]\n",
    "    bff = butterworth(d1, d2, n)\n",
    "    I_fft = np.fft.fft2(I)\n",
    "    I_fft_shift = np.fft.fftshift(I_fft)\n",
    "    I_fft_shift_filt = I_fft_shift*bff # filter with the Butterworth filter\n",
    "    I_fft_filt = np.fft.ifftshift(I_fft_shift_filt)\n",
    "    I_filt = np.fft.ifft2(I_fft_filt)\n",
    "    return I_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_floc_proxy(frame, d1, d2, n):\n",
    "    I_filt = frame_filter(frame, d1, d2, n)\n",
    "    return np.array([(np.absolute(I_filt)>4000).sum()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show example for one frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_filt = frame_filter(frame, d1, d2, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(6, 6))\n",
    "imgplot = plt.imshow(np.absolute(I_filt)>4000, cmap='gray')\n",
    "plt.title('floc_proxy value = %i' % (np.absolute(I_filt)>4000).sum());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assemble a new Dask array including our computation using map_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floc_proxy = dsa.map_blocks(calc_floc_proxy, delayed_frame_array, d1, d2, n, dtype='i8', drop_axis=[1,2])\n",
    "floc_proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the floc_proxy (subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = floc_proxy[0:40].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start a Dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_kubernetes import KubeCluster\n",
    "cluster = KubeCluster(n_workers=30)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = floc_proxy[0:400].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of images: %i' % len(floc_proxy))\n",
    "print('Size of dataset (GB): %i' % round(len(floc_proxy)*1080*1920*2/1024/1024/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = floc_proxy.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a timestamp for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbcamhd = pd.read_json('/home/jovyan/rte-camhd/tim/dbcamhd.json', orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, math\n",
    "import matplotlib.dates as dates\n",
    "frame_timestamp = []\n",
    "for i, filename in enumerate(filenames):    \n",
    "    timestamp = dbcamhd['timestamp'][dbcamhd.filename == filename].iloc[0]\n",
    "    timestamp = timestamp + frame_numbers[i]/29.97\n",
    "    dt = datetime.datetime.fromtimestamp(timestamp)\n",
    "    frame_timestamp.append(dates.date2num(dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a two-dimensional multivariate histogram of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=11)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(14, 6)\n",
    "fig.frameon = False\n",
    "hb1 = ax.hexbin(frame_timestamp, results, vmin=0.1, vmax=2, bins='log', linewidths=0.25,\n",
    "  gridsize=(225,4500), mincnt=1, cmap=plt.cm.BuPu)\n",
    "fig.colorbar(hb1)\n",
    "ax.set_ylim([0, 8000])\n",
    "ax.set_xlim([frame_timestamp[0],frame_timestamp[-1]])\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "months = dates.MonthLocator()  # every month\n",
    "monthsFmt = dates.DateFormatter('%b %Y')\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(monthsFmt)\n",
    "plt.ylabel('Floc Proxy Value');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting in mid-June a large \"floc event\" occurs where the floc proxy values increase on average by about a factor of ten. The cause of this floc event is being investigated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    " - [Pangeo](http://pangeo-data.org/)\n",
    " - [PyCamHD](https://github.com/tjcrone/pycamhd)\n",
    " - [CamHD Raw Data Archive](https://rawdata.oceanobservatories.org/files/RS03ASHS/PN03B/06-CAMHDA301)\n",
    " - [AGU Abstract](https://agu.confex.com/agu/fm16/meetingapp.cgi/Paper/192670)\n",
    " - [AGU Poster](https://drive.google.com/open?id=0B-dWW4GM434obGpTM0FZME10Nkk)\n",
    " - [Dask](http://dask.pydata.org/en/latest/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
