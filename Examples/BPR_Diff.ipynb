{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPR Data - Difference plots NEMO 2013- 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Information Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "# import numpy as np\n",
    "# import datetime\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.dates as dates\n",
    "# from matplotlib import pyplot\n",
    "# from pylab import rcParams\n",
    "# import pickle as pk\n",
    "# import gc\n",
    "# import requests \n",
    "# import matplotlib.gridspec as gridspec\n",
    "# import netCDF4 as nc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nemo Center "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_file = '/home/jovyan/data/botpt/bpr_files/Axial_Deformation/nemo2013-2015-BPR-Center-15sec-driftcorr-detided-lpf.txt'\n",
    "df_nemoC = pd.read_csv(bpr_file, dtype = object)\n",
    "df_nemoC.index = df_nemoC.Date\n",
    "del df_nemoC['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nemoC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_nemoC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://hvplot.pyviz.org/user_guide/Introduction.html\n",
    "\n",
    "https://hvplot.pyviz.org/user_guide/Plotting.html\n",
    "\n",
    "https://hvplot.pyviz.org/user_guide/Subplots.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nemoC.hvplot(x='Date', y='DriftCorrRawDep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nemo South"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_file = '/home/jovyan/data/botpt/bpr_files/Axial_Deformation/nemo2013-2015-BPR-Center-15sec-driftcorr-detided-lpf.txt'\n",
    "df_nemoS = pd.read_csv(bpr_file, dtype = object)\n",
    "df_nemoS.index = df_nemoS.Date\n",
    "del df_nemoS['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nemoS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list comprehention\n",
    "epoch= [i.timestamp() for i in df_tides.index.to_pydatetime()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tides['epoch'] = epoch\n",
    "df_tides.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Downsampled BOTPT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/jovyan/data/botpt/bottom_pressure15S_E11.pkl', 'rb') as E:\n",
    "    botpt_data = pk.load(E)\n",
    "df_botpt = pd.DataFrame(botpt_data)\n",
    "df_botpt['bottom_pressure'] = df_botpt['bottom_pressure'].astype(float)\n",
    "df_botpt['depth']=df_botpt['bottom_pressure'].astype(float) * 0.670\n",
    "#MJ03F_cal_depths = [MJ03F_pressure * 0.0670 for MJ03F_pressure in MJ03F_pressure]\n",
    "#list comprehention\n",
    "epoch= [i.timestamp() for i in df_botpt.index.to_pydatetime()]\n",
    "df_botpt['epoch'] = epoch\n",
    "df_botpt= df_botpt.sort_index()\n",
    "df_botpt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_botpt.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine BOTPT with Tide Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subsetTides = df_tides.loc['2015-01-1 00:00:00':'2018-10-31 00:00:00']\n",
    "df_subsetBOTPT = df_botpt.loc['2015-01-1 00:00:00':'2018-10-31 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subsetBOTPT['tides'] = df_subsetTides.height\n",
    "df_subsetBOTPT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subsetBOTPT['dtide']=  df_subsetBOTPT['depth'] - df_subsetBOTPT['tides']\n",
    "df_subsetBOTPT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time = list(df_botpt.index.values)\n",
    "height = list(df_subsetBOTPT['dtide'].values)\n",
    "\n",
    "time_int = []\n",
    "time = list(pd.to_datetime(df_subsetBOTPT.index.values))\n",
    "for i in time:\n",
    "    i = np.datetime64(i).astype(datetime.datetime)\n",
    "    time_int.append(dates.date2num(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(28, 6)\n",
    "hb1 = ax.hexbin(time_int, height, vmin=0, vmax=30, gridsize=(1500,100), mincnt=1, cmap='Greens', linewidths=0)\n",
    "fig.colorbar(hb1, pad = 0.01)\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "ax.set_xlim(datetime.datetime(2015, 1, 1, 0, 0),datetime.datetime(2018, 10, 31, 0, 0))\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(monthsFmt)\n",
    "ax.xaxis.set_minor_locator(years)\n",
    "ax.xaxis.set_minor_formatter(yearsFmt)\n",
    "plt.tight_layout()\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "plt.savefig('Figures/StationE_2015thruPresent.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: the big jumps are bad data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subsetBOTPT['date']=pd.DatetimeIndex(df_subsetBOTPT.index).date\n",
    "df_subsetBOTPT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Groupby to create one day mean measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_botptMean=df_subsetBOTPT.groupby('date').mean()\n",
    "df_botptMean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create time and height vectors for plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = list(df_botptMerge.index.values)\n",
    "#height = x.tolist()\n",
    "height = df_botptMean['dtide'].tolist()\n",
    "time_int = []\n",
    "time = list(pd.to_datetime(df_botptMean.index.values))\n",
    "for i in time:\n",
    "    i = np.datetime64(i).astype(datetime.datetime)\n",
    "    time_int.append(dates.date2num(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot One Day Measurements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(28, 7)\n",
    "hb1 = ax.plot(time_int, height)\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "ax.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 15, 0, 0))\n",
    "ax.set_ylim(1501.25,1502.2)\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(monthsFmt)\n",
    "ax.xaxis.set_minor_locator(years)\n",
    "ax.xaxis.set_minor_formatter(yearsFmt)\n",
    "plt.tight_layout()\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "plt.savefig('Figures/StationF_2017_2018_1dayAve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bad data still visible;\n",
    "#### We will remove these using a moving average filter that chops off the 95th percentile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movingaverage(interval, window_size):\n",
    "    window= np.ones(int(window_size))/float(window_size)\n",
    "    return np.convolve(interval, window, 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth data using rolling window that chops off 95th percentile \n",
    "TwelveWeek = list(movingaverage(df_botptMean['dtide'],28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(time_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(28, 7)\n",
    "hb1 = ax.plot(time_int, TwelveWeek,linewidth=5)\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "ax.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 15, 0, 0))\n",
    "ax.set_ylim(1501.6,1502.2)\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(monthsFmt)\n",
    "ax.xaxis.set_minor_locator(years)\n",
    "ax.xaxis.set_minor_formatter(yearsFmt)\n",
    "plt.tight_layout()\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "plt.savefig('Figures/StationF_2017_2018_1dayAve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Seismic Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seismic_file = '/home/jovyan/data/hypo71_2018.dat'\n",
    "df_seismic_data = pd.read_csv(seismic_file, delim_whitespace=True, dtype=object)\n",
    "df_seismic_data['datetime'] = df_seismic_data['yyyymmdd'] + 'T' + \\\n",
    "            df_seismic_data['HHMM'].str.slice(start=0, stop=2) + ':' + \\\n",
    "            df_seismic_data['HHMM'].str.slice(start=2) \n",
    "df_seismic_data.index = pd.to_datetime(df_seismic_data['datetime'].values)\n",
    "df_seismic_data['datetime'] = pd.to_datetime(df_seismic_data['datetime'].values)\n",
    "df_seismic_data = df_seismic_data.loc['2017-01-1 00:00:00':'2018-10-31 00:00:00']\n",
    "del df_seismic_data['yyyymmdd']\n",
    "del df_seismic_data['HHMM']\n",
    "del df_seismic_data['SSS.SS']\n",
    "del df_seismic_data['MW']\n",
    "del df_seismic_data['NWR']\n",
    "del df_seismic_data['GAP']\n",
    "del df_seismic_data['DMIN']\n",
    "del df_seismic_data['ERH']\n",
    "del df_seismic_data['ERZ']\n",
    "del df_seismic_data['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seismic_data.datetime.astype(np.int64).values/1e64\n",
    "df_seismic_data['date'] =pd.DatetimeIndex(df_seismic_data.datetime).date\n",
    "#df_seismic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe with Earthquake frequency (count per day)\n",
    "##### Note: Days with zero earthquakes are not represented in this timeseries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eqMean=df_seismic_data.groupby('date').count()\n",
    "del df_eqMean['Lat(D']\n",
    "del df_eqMean['M)']\n",
    "del df_eqMean['Lon(D']\n",
    "del df_eqMean['M).1']\n",
    "del df_eqMean['Depth']\n",
    "del df_eqMean['RMS']\n",
    "del df_eqMean['PMom']\n",
    "del df_eqMean['SMom']\n",
    "df_eqMean['count']= df_eqMean.datetime\n",
    "del df_eqMean['datetime']\n",
    "df_eqMean.columns.name = df_eqMean.index.name\n",
    "df_eqMean.index.name = None\n",
    "#df_eqMean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample. Add days to our earthquake data where there were zero earthquakes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.date_range('2017-01-1 00:00:00', '2018-10-31 00:00:00')\n",
    "\n",
    "s = df_eqMean\n",
    "\n",
    "s.index = pd.DatetimeIndex(s.index)\n",
    "\n",
    "s = s.reindex(idx, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create time and count vectors earthquake frequency vectors for plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df_eqMean['count'].tolist()\n",
    "time_eq = []\n",
    "time = list(pd.to_datetime(df_eqMean.index.values))\n",
    "for i in time:\n",
    "    i = np.datetime64(i).astype(datetime.datetime)\n",
    "    time_eq.append(dates.date2num(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth data using rolling window that chops off 95th percentile \n",
    "count_av = list(movingaverage(df_eqMean['count'],21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of Earthquake Frequency and Inflation Rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig4, (ax1,ax2) = plt.subplots(2,1)\n",
    "fig4.set_size_inches(28, 14)\n",
    "hb1 = ax1.plot(time_int, TwelveWeek,linewidth=5)\n",
    "ax1.yaxis.grid(True)\n",
    "ax1.xaxis.grid(True)\n",
    "ax1.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 15, 0, 0))\n",
    "ax1.set_ylim(1501.6,1502.2)\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax1.xaxis.set_major_locator(months)\n",
    "ax1.xaxis.set_major_formatter(monthsFmt)\n",
    "ax1.xaxis.set_minor_locator(years)\n",
    "ax1.xaxis.set_minor_formatter(yearsFmt)\n",
    "ax1.set_title('Caldera Inflation', fontsize=18, fontweight = 'bold')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "hb1 = ax2.plot(time_eq, count)\n",
    "hb2 = ax2.plot(time_eq, count_av, linewidth=5)\n",
    "ax2.yaxis.grid(True)\n",
    "ax2.xaxis.grid(True)\n",
    "ax2.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 15, 0, 0))\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax2.xaxis.set_major_locator(months)\n",
    "ax2.xaxis.set_major_formatter(monthsFmt)\n",
    "ax2.xaxis.set_minor_locator(years)\n",
    "ax2.xaxis.set_minor_formatter(yearsFmt)\n",
    "ax2.set_title('Daily Seismicity', fontsize=18, fontweight = 'bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=90)\n",
    "plt.suptitle('Centeral Caldera Inflation and Seismicity', fontsize=32, color= 'blue', fontweight = 'bold')\n",
    "plt.subplots_adjust(top=0.90)\n",
    "#plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
