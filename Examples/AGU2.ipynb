{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: The relationship between post- 2015 eruption deformation and seismicity rates since the 2015 eruption at Axial Seamount\n",
    "\n",
    "# Authors: J. Natalie, D. C. Soule, T. J. Crone, W. W. Chadwick Jr., W. S. D. Wilcock\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "#### The Ocean Observatories Initiative Cabled Array (OOI-CA) provides the opportunity to use new approaches to observe geological  processes  at Axial Seamount, an active submarine volcano on the Juan de Fuca spreading ridge located ~300 miles off the coast of Oregon. The OOI-CA provides a suite of interdisciplinary real-time datasets from seismic and geodetic networks and a variety of instruments in two hydrothermal fields with which we can examine system-level processes governing the volcano-marine environment. The geophysical networks comprise 4 Pressure/Tilt (BOTPT) instruments that detect the rise, fall, and tilt of the seafloor as it responds to the movement of magma within the crust and 7 seismometers to monitor earthquakes. In order to better understand the patterns of magma storage and delivery beneath the Axial summit caldera and provide constraints for the development of improved predictive models, we are examining short-term variations in the rates of deformation and seismicity and how well they co-vary during the inter-eruption time period. We will also investigate apparent “pauses” in the magma supply rate when the rate of seismicity and deformation have both dropped. On the time-scale of years, seafloor deformation measurements show a relatively steady rate of inflation of the seafloor between eruptions that can be interpreted as reflecting the rate that magma is supplied to the sub-caldera magma reservoir (Nooner and Chadwick 2016). However, on the time-scale of weeks to months, the rate is more variable. Similarly, the rate of earthquakes detected by the OOI seismometer network also varies with time. It was very low immediately after the 2015 eruption, but it has increased markedly over the past year, and based on the observations of prior eruptive cycles, it is expected to increase by several orders of magnitude before the next eruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = \"https://43d897265kne3ed0qv2ecjw2-wpengine.netdna-ssl.com/wp-content/uploads/2016/12/web1_161216_ADW_Underwater_Volcano_Hero1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load map of Axial caldera showing locations of BOTPT instruments (red circles)\n",
    "from IPython.display import Image\n",
    "Image(url = \"https://www.pmel.noaa.gov/eoi/rsn/Axial-2017-OOI-caldera-ed-sm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zoomed in map of Axial caldera\n",
    "from IPython.display import Image\n",
    "Image(url = \"https://www.pmel.noaa.gov/eoi/rsn/Axial-2017-OOI-zoom-ed-sm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "from matplotlib import pyplot\n",
    "from pylab import rcParams\n",
    "import pickle as pk\n",
    "import gc\n",
    "import requests \n",
    "import matplotlib.gridspec as gridspec\n",
    "import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_file = '/home/jovyan/data/tide/pred_F.txt'\n",
    "df_tides = pd.read_csv(tide_file, delim_whitespace=True, dtype = object)\n",
    "df_tides['datetime']=df_tides['year'] + '-' + df_tides['month'] + '-' + df_tides['day'] + \\\n",
    "            'T' + df_tides['hour'] + ':' + df_tides['minute'] + ':' + df_tides['second']\n",
    "#df_tides_E = pd.DataFrame(tides_E)\n",
    "df_tides.index=pd.to_datetime(df_tides['datetime'].values)\n",
    "#df_tides_E.index = df_tides_E['parsed_time']\n",
    "del df_tides['year']\n",
    "del df_tides['month']\n",
    "del df_tides['day']\n",
    "del df_tides['hour']\n",
    "del df_tides['minute']\n",
    "del df_tides['second']\n",
    "del df_tides['datetime']\n",
    "df_tides['height'] = df_tides['height'].astype(float)\n",
    "#df_tides_E['height'] = df_tides_E['height'].to_pandas().resample('T').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list comprehention\n",
    "epoch= [i.timestamp() for i in df_tides.index.to_pydatetime()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tides['epoch'] = epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/jovyan/data/botpt/bottom_pressure15S_F11.pkl', 'rb') as F:\n",
    "    botpt_data = pk.load(F)\n",
    "df_botpt = pd.DataFrame(botpt_data)\n",
    "df_botpt['bottom_pressure'] = df_botpt['bottom_pressure'].astype(float)\n",
    "df_botpt['depth']=df_botpt['bottom_pressure'].astype(float) * 0.670\n",
    "#MJ03F_cal_depths = [MJ03F_pressure * 0.0670 for MJ03F_pressure in MJ03F_pressure]\n",
    "#list comprehention\n",
    "epoch= [i.timestamp() for i in df_botpt.index.to_pydatetime()]\n",
    "df_botpt['epoch'] = epoch\n",
    "df_botpt= df_botpt.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine BOTPT with Tide Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subsetTides = df_tides.loc['2015-01-1 00:00:00':'2018-10-31 00:00:00']\n",
    "df_subsetBOTPT = df_botpt.loc['2015-01-1 00:00:00':'2018-10-31 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subsetBOTPT['tides'] = df_subsetTides.height\n",
    "df_subsetBOTPT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subsetBOTPT['dtide']=  df_subsetBOTPT['depth'] - df_subsetBOTPT['tides']\n",
    "df_subsetBOTPT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas\n",
    "df_subsetBOTPT.hvplot(x='epoch', y='dtide', datashade=True)\n",
    "# hvplot.save(Examples, 'test.png')\n",
    "# df_subsetBOTPT['dtide'].hvplot(x='epoch', y='dtide', datashade=True)\n",
    "# df_subsetBOTPT['dtide'].hvplot.line(x='epoch', y='detided depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #time = list(df_botpt.index.values)\n",
    "# height = list(df_subsetBOTPT['dtide'].values)\n",
    "\n",
    "# time_int = []\n",
    "# time = list(pd.to_datetime(df_subsetBOTPT.index.values))\n",
    "# for i in time:\n",
    "#     i = np.datetime64(i).astype(datetime.datetime)\n",
    "#     time_int.append(dates.date2num(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close()\n",
    "# fig, ax = plt.subplots()\n",
    "# fig.set_size_inches(28, 6)\n",
    "# hb1 = ax.hexbin(time_int, height, vmin=0, vmax=30, gridsize=(1500,100), mincnt=1, cmap='Greens', linewidths=0)\n",
    "# fig.colorbar(hb1, pad = 0.01)\n",
    "# ax.yaxis.grid(True)\n",
    "# ax.xaxis.grid(True)\n",
    "# ax.set_xlim(datetime.datetime(2015, 1, 1, 0, 0),datetime.datetime(2018, 10, 31, 0, 0))\n",
    "# years = dates.YearLocator()\n",
    "# months = dates.MonthLocator()\n",
    "# yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "# monthsFmt = dates.DateFormatter('%b')\n",
    "# ax.xaxis.set_major_locator(months)\n",
    "# ax.xaxis.set_major_formatter(monthsFmt)\n",
    "# ax.xaxis.set_minor_locator(years)\n",
    "# ax.xaxis.set_minor_formatter(yearsFmt)\n",
    "# plt.tight_layout()\n",
    "# plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.show()\n",
    "# plt.savefig('Figures/StationE_2015thruPresent.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subsetBOTPT['date']=pd.DatetimeIndex(df_subsetBOTPT.index).date\n",
    "df_subsetBOTPT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Groupby to create one day mean measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_botptMean=df_subsetBOTPT.groupby('date').mean()\n",
    "# df_botptMean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_botptMean.hvplot(x='epoch', y='dtide', datashade=True)\n",
    "# df_botptMean.hvplot(x='epoch', y='dtide', height=500, datashade=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create time and height vectors for plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = list(df_botptMerge.index.values)\n",
    "#height = x.tolist()\n",
    "# height = df_botptMean['dtide'].tolist()\n",
    "# time_int = []\n",
    "# time = list(pd.to_datetime(df_botptMean.index.values))\n",
    "# for i in time:\n",
    "#     i = np.datetime64(i).astype(datetime.datetime)\n",
    "#     time_int.append(dates.date2num(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close()\n",
    "# fig, ax = plt.subplots()\n",
    "# fig.set_size_inches(28, 7)\n",
    "# hb1 = ax.plot(time_int, height)\n",
    "# ax.yaxis.grid(True)\n",
    "# ax.xaxis.grid(True)\n",
    "# ax.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 15, 0, 0))\n",
    "# ax.set_ylim(1501.25,1502.2)\n",
    "# years = dates.YearLocator()\n",
    "# months = dates.MonthLocator()\n",
    "# yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "# monthsFmt = dates.DateFormatter('%b')\n",
    "# ax.xaxis.set_major_locator(months)\n",
    "# ax.xaxis.set_major_formatter(monthsFmt)\n",
    "# ax.xaxis.set_minor_locator(years)\n",
    "# ax.xaxis.set_minor_formatter(yearsFmt)\n",
    "# plt.tight_layout()\n",
    "# plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.show()\n",
    "# plt.savefig('Figures/StationF_2017_2018_1dayAve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movingaverage(interval, window_size):\n",
    "    window= np.ones(int(window_size))/float(window_size)\n",
    "    return np.convolve(interval, window, 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth data using rolling window that chops off 95th percentile \n",
    "TwelveWeek = list(movingaverage(df_botptMean['dtide'],28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(time_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Seismic Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seismic_file = '/home/jovyan/data/hypo71_2018.dat'\n",
    "df_seismic_data = pd.read_csv(seismic_file, delim_whitespace=True, dtype=object)\n",
    "df_seismic_data['datetime'] = df_seismic_data['yyyymmdd'] + 'T' + \\\n",
    "            df_seismic_data['HHMM'].str.slice(start=0, stop=2) + ':' + \\\n",
    "            df_seismic_data['HHMM'].str.slice(start=2) \n",
    "df_seismic_data.index = pd.to_datetime(df_seismic_data['datetime'].values)\n",
    "df_seismic_data['datetime'] = pd.to_datetime(df_seismic_data['datetime'].values)\n",
    "df_seismic_data = df_seismic_data.loc['2017-01-1 00:00:00':'2018-10-31 00:00:00']\n",
    "del df_seismic_data['yyyymmdd']\n",
    "del df_seismic_data['HHMM']\n",
    "del df_seismic_data['SSS.SS']\n",
    "del df_seismic_data['MW']\n",
    "del df_seismic_data['NWR']\n",
    "del df_seismic_data['GAP']\n",
    "del df_seismic_data['DMIN']\n",
    "del df_seismic_data['ERH']\n",
    "del df_seismic_data['ERZ']\n",
    "del df_seismic_data['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seismic_data.datetime.astype(np.int64).values/1e64\n",
    "df_seismic_data['date'] =pd.DatetimeIndex(df_seismic_data.datetime).date\n",
    "#df_seismic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe with Earthquake frequency (count per day)\n",
    "##### Note: Days with zero earthquakes are not represented in this timeseries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eqMean=df_seismic_data.groupby('date').count()\n",
    "del df_eqMean['Lat(D']\n",
    "del df_eqMean['M)']\n",
    "del df_eqMean['Lon(D']\n",
    "del df_eqMean['M).1']\n",
    "del df_eqMean['Depth']\n",
    "del df_eqMean['RMS']\n",
    "del df_eqMean['PMom']\n",
    "del df_eqMean['SMom']\n",
    "df_eqMean['count']= df_eqMean.datetime\n",
    "del df_eqMean['datetime']\n",
    "df_eqMean.columns.name = df_eqMean.index.name\n",
    "df_eqMean.index.name = None\n",
    "#df_eqMean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample. Add days to our earthquake data where there were zero earthquakes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.date_range('2017-01-1 00:00:00', '2018-10-31 00:00:00')\n",
    "\n",
    "s = df_eqMean\n",
    "\n",
    "s.index = pd.DatetimeIndex(s.index)\n",
    "\n",
    "s = s.reindex(idx, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create time and count vectors earthquake frequency vectors for plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df_eqMean['count'].tolist()\n",
    "time_eq = []\n",
    "time = list(pd.to_datetime(df_eqMean.index.values))\n",
    "for i in time:\n",
    "    i = np.datetime64(i).astype(datetime.datetime)\n",
    "    time_eq.append(dates.date2num(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth data using rolling window that chops off 95th percentile \n",
    "count_av = list(movingaverage(df_eqMean['count'],21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of Earthquake Frequency and Inflation Rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_botptMean.hvplot(x='epoch', y='dtide', datashade=True)\n",
    "# df_botptMean.hvplot(x='epoch', y='dtide', height=500, datashade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close()\n",
    "# fig4, (ax1,ax2) = plt.subplots(2,1)\n",
    "# fig4.set_size_inches(28, 14)\n",
    "# hb1 = ax1.plot(time_int, TwelveWeek,linewidth=5)\n",
    "# ax1.yaxis.grid(True)\n",
    "# ax1.xaxis.grid(True)\n",
    "# ax1.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 15, 0, 0))\n",
    "# ax1.set_ylim(1501.6,1502.2)\n",
    "# years = dates.YearLocator()\n",
    "# months = dates.MonthLocator()\n",
    "# yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "# monthsFmt = dates.DateFormatter('%b')\n",
    "# ax1.xaxis.set_major_locator(months)\n",
    "# ax1.xaxis.set_major_formatter(monthsFmt)\n",
    "# ax1.xaxis.set_minor_locator(years)\n",
    "# ax1.xaxis.set_minor_formatter(yearsFmt)\n",
    "# ax1.set_title('Caldera Inflation', fontsize=18, fontweight = 'bold')\n",
    "# ax1.invert_yaxis()\n",
    "\n",
    "# hb1 = ax2.plot(time_eq, count)\n",
    "# hb2 = ax2.plot(time_eq, count_av, linewidth=5)\n",
    "# ax2.yaxis.grid(True)\n",
    "# ax2.xaxis.grid(True)\n",
    "# ax2.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 15, 0, 0))\n",
    "# years = dates.YearLocator()\n",
    "# months = dates.MonthLocator()\n",
    "# yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "# monthsFmt = dates.DateFormatter('%b')\n",
    "# ax2.xaxis.set_major_locator(months)\n",
    "# ax2.xaxis.set_major_formatter(monthsFmt)\n",
    "# ax2.xaxis.set_minor_locator(years)\n",
    "# ax2.xaxis.set_minor_formatter(yearsFmt)\n",
    "# ax2.set_title('Daily Seismicity', fontsize=18, fontweight = 'bold')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.setp(ax1.xaxis.get_majorticklabels(), rotation=90)\n",
    "# plt.suptitle('Comparison Between Inflation and Seismicity', fontsize=32, color= 'blue', fontweight = 'bold')\n",
    "# plt.subplots_adjust(top=0.90)\n",
    "# #plt.gca().invert_yaxis()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Depth Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/jovyan/data/botpt/bottom_pressure15S_F11.pkl', 'rb') as E:\n",
    "    botpt_data = pk.load(E)\n",
    "df_botpt = pd.DataFrame(botpt_data)\n",
    "df_botpt['bottom_pressure'] = df_botpt['bottom_pressure'].astype(float)\n",
    "df_botpt['depth']=df_botpt['bottom_pressure'].astype(float) * 0.670\n",
    "#MJ03F_cal_depths = [MJ03F_pressure * 0.0670 for MJ03F_pressure in MJ03F_pressure]\n",
    "#list comprehention\n",
    "epoch= [i.timestamp() for i in df_botpt.index.to_pydatetime()]\n",
    "df_botpt['epoch'] = epoch\n",
    "df_botpt= df_botpt.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/jovyan/data/botpt/bottom_pressure15S_E11.pkl', 'rb') as E:\n",
    "    botpt_data = pk.load(E)\n",
    "df_botptE = pd.DataFrame(botpt_data)\n",
    "df_botptE['bottom_pressure'] = df_botptE['bottom_pressure'].astype(float)\n",
    "df_botptE['depth']=df_botptE['bottom_pressure'].astype(float) * 0.670\n",
    "#MJ03F_cal_depths = [MJ03F_pressure * 0.0670 for MJ03F_pressure in MJ03F_pressure]\n",
    "#list comprehention\n",
    "epoch= [i.timestamp() for i in df_botptE.index.to_pydatetime()]\n",
    "df_botptE['epoch'] = epoch\n",
    "df_botptE= df_botptE.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning up the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_botptE['epoch']\n",
    "del df_botptE['bottom_pressure']\n",
    "del df_botpt['epoch']\n",
    "del df_botpt['bottom_pressure']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge BOTPT E and BOTPT F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(df_botpt, df_botptE,how='outer', indicator=True, left_index=True, right_index=True, suffixes=('_F', '_E'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_botptMerge = test[test['_merge'] == 'both']\n",
    "del df_botptMerge['_merge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_botptMerge = df_botptMerge.loc['2017-01-1 00:00:00':'2018-10-31 00:00:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Depth difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthDiff = df_botptMerge['depth_E'].values - df_botptMerge['depth_F'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_botptMerge['diff'] = depthDiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create time and height vectors for plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_botptMerge['date']=pd.DatetimeIndex(df_botptMerge.index).date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_botptMean=df_botptMerge.groupby('date').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create time and height vectors for plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = list(df_botptMerge.index.values)\n",
    "#height = x.tolist()\n",
    "height = df_botptMean['diff'].tolist()\n",
    "time_int = []\n",
    "time = list(pd.to_datetime(df_botptMean.index.values))\n",
    "for i in time:\n",
    "    i = np.datetime64(i).astype(datetime.datetime)\n",
    "    time_int.append(dates.date2num(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot One Day Measurements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(28, 6)\n",
    "hb1 = ax.plot(time_int, height)\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "ax.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 31, 0, 0))\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(monthsFmt)\n",
    "ax.xaxis.set_minor_locator(years)\n",
    "ax.xaxis.set_minor_formatter(yearsFmt)\n",
    "plt.tight_layout()\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "#plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haley Cabaniss with significant help from Bill Chadwick, Zach Billings, Sage Lichtenwainer, and Liana Vaccari\n",
    "\n",
    "### Bill Chadwick recently noticed spikes in BOTPT data for 3 of the instruments on the cabled array. He notified Dana Manalung, who attributed the spikes to a grounding problem in the junction boxes. During a recent cruise (early July 2018) the junction boxes were changed and the 3 BOTPT instruments (MJ03B, MJ03B, MJ03F) were grounded using an alternatitve method. \n",
    "\n",
    "### Remove Spikes \n",
    "These drop outs come from slight mismatches between the stations. To remove them I have identified the spikes where the data indicates an unreasonable change in seafloor height and replaced them with an adjacent data point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_data = np.array(height)\n",
    "time_array = np.array(time)\n",
    "\n",
    "cleaner_data = []\n",
    "cleaner_time = []\n",
    "\n",
    "# i = 0\n",
    "# while i < len(weird_data):\n",
    "#     if (weird_data[i] - weird_data[i-1] > 2\n",
    "\n",
    "length = len(weird_data)\n",
    "\n",
    "i = 0\n",
    "while i < length:\n",
    "    j = i+2\n",
    "    while j < length:\n",
    "        if np.abs(weird_data[i] - weird_data[j]) < .05:\n",
    "            cleaner_data.append(weird_data[j])\n",
    "            cleaner_time.append(time_array[j])\n",
    "            break\n",
    "        else:\n",
    "            j += 1\n",
    "    i = j\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between plots with and without spikes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig3, (ax1,ax2) = plt.subplots(2,1)\n",
    "fig3.set_size_inches(28, 14)\n",
    "hb1 = ax1.plot(time_int, height, linewidth=5)\n",
    "ax1.yaxis.grid(True)\n",
    "ax1.xaxis.grid(True)\n",
    "ax1.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 31, 0, 0))\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax1.xaxis.set_major_locator(months)\n",
    "ax1.xaxis.set_major_formatter(monthsFmt)\n",
    "ax1.xaxis.set_minor_locator(years)\n",
    "ax1.xaxis.set_minor_formatter(yearsFmt)\n",
    "\n",
    "hb1 = ax2.plot(cleaner_time, cleaner_data, linewidth=5)\n",
    "ax2.yaxis.grid(True)\n",
    "ax2.xaxis.grid(True)\n",
    "ax2.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 31, 0, 0))\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax2.xaxis.set_major_locator(months)\n",
    "ax2.xaxis.set_major_formatter(monthsFmt)\n",
    "ax2.xaxis.set_minor_locator(years)\n",
    "ax2.xaxis.set_minor_formatter(yearsFmt)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=90)\n",
    "plt.suptitle('Removing Outliers', fontsize=32, color= 'red', fontweight = 'bold')\n",
    "plt.subplots_adjust(top=0.90)\n",
    "#plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Seismic Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seismic_file = '/home/jovyan/data/hypo71_2018.dat'\n",
    "df_seismic_data = pd.read_csv(seismic_file, delim_whitespace=True, dtype=object)\n",
    "df_seismic_data['datetime'] = df_seismic_data['yyyymmdd'] + 'T' + \\\n",
    "            df_seismic_data['HHMM'].str.slice(start=0, stop=2) + ':' + \\\n",
    "            df_seismic_data['HHMM'].str.slice(start=2) \n",
    "df_seismic_data.index = pd.to_datetime(df_seismic_data['datetime'].values)\n",
    "df_seismic_data['datetime'] = pd.to_datetime(df_seismic_data['datetime'].values)\n",
    "df_seismic_data = df_seismic_data.loc['2017-01-1 00:00:00':'2018-10-31 00:00:00']\n",
    "del df_seismic_data['yyyymmdd']\n",
    "del df_seismic_data['HHMM']\n",
    "del df_seismic_data['SSS.SS']\n",
    "del df_seismic_data['MW']\n",
    "del df_seismic_data['NWR']\n",
    "del df_seismic_data['GAP']\n",
    "del df_seismic_data['DMIN']\n",
    "del df_seismic_data['ERH']\n",
    "del df_seismic_data['ERZ']\n",
    "del df_seismic_data['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seismic_data.datetime.astype(np.int64).values/1e64\n",
    "df_seismic_data['date'] =pd.DatetimeIndex(df_seismic_data.datetime).date\n",
    "df_seismic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe with Earthquake frequency (count per day)\n",
    "##### Note: Days with zero earthquakes are not represented in this timeseries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eqMean=df_seismic_data.groupby('date').count()\n",
    "del df_eqMean['Lat(D']\n",
    "del df_eqMean['M)']\n",
    "del df_eqMean['Lon(D']\n",
    "del df_eqMean['M).1']\n",
    "del df_eqMean['Depth']\n",
    "del df_eqMean['RMS']\n",
    "del df_eqMean['PMom']\n",
    "del df_eqMean['SMom']\n",
    "df_eqMean['count']= df_eqMean.datetime\n",
    "del df_eqMean['datetime']\n",
    "df_eqMean.columns.name = df_eqMean.index.name\n",
    "df_eqMean.index.name = None\n",
    "df_eqMean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample. Add days to our earthquake data where there were zero earthquakes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.date_range('2017-01-1 00:00:00', '2018-10-31 00:00:00')\n",
    "\n",
    "s = df_eqMean\n",
    "\n",
    "s.index = pd.DatetimeIndex(s.index)\n",
    "\n",
    "s = s.reindex(idx, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create time and count vectors earthquake frequency vectors for plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df_eqMean['count'].tolist()\n",
    "time_int = []\n",
    "time = list(pd.to_datetime(df_eqMean.index.values))\n",
    "for i in time:\n",
    "    i = np.datetime64(i).astype(datetime.datetime)\n",
    "    time_int.append(dates.date2num(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movingaverage(interval, window_size):\n",
    "    window= np.ones(int(window_size))/float(window_size)\n",
    "    return np.convolve(interval, window, 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth data using rolling window that chops off 95th percentile \n",
    "count_av = list(movingaverage(df_eqMean['count'],21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Earthquake Frequency and Inflation Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "# fig4, (ax1) = plt.subplots(1,1)\n",
    "fig4, (ax1,ax2) = plt.subplots(2,1)\n",
    "fig4.set_size_inches(28, 14)\n",
    "hb1 = ax1.plot(cleaner_time, cleaner_data, linewidth=5)\n",
    "ax1.yaxis.grid(True)\n",
    "ax1.xaxis.grid(True)\n",
    "ax1.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 31, 0, 0))\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax1.xaxis.set_major_locator(months)\n",
    "ax1.xaxis.set_major_formatter(monthsFmt)\n",
    "ax1.xaxis.set_minor_locator(years)\n",
    "ax1.xaxis.set_minor_formatter(yearsFmt)\n",
    "ax1.set_title('Caldera Inflation', fontsize=18, fontweight = 'bold')\n",
    "\n",
    "\n",
    "hb1 = ax2.plot(time, count)\n",
    "hb2 = ax2.plot(time, count_av, linewidth=5)\n",
    "ax2.yaxis.grid(True)\n",
    "ax2.xaxis.grid(True)\n",
    "ax2.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 31, 0, 0))\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax2.xaxis.set_major_locator(months)\n",
    "ax2.xaxis.set_major_formatter(monthsFmt)\n",
    "ax2.xaxis.set_minor_locator(years)\n",
    "ax2.xaxis.set_minor_formatter(yearsFmt)\n",
    "ax2.set_title('Daily Seismicity', fontsize=18, fontweight = 'bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=90)\n",
    "plt.suptitle('Comparison Between Inflation and Seismicity', fontsize=32, color= 'blue', fontweight = 'bold')\n",
    "plt.subplots_adjust(top=0.90)\n",
    "#plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
