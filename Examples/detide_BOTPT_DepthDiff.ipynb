{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOTPT Data detide DepthDifference\n",
    "\n",
    "#### This method is detailed here: https://www.pmel.noaa.gov/eoi/rsn/diffs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load map of Axial caldera showing locations of BOTPT instruments (red circles)\n",
    "from IPython.display import Image\n",
    "Image(url = \"https://www.pmel.noaa.gov/eoi/rsn/Axial-2017-OOI-caldera-ed-sm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zoomed in map of Axial caldera\n",
    "from IPython.display import Image\n",
    "Image(url = \"https://www.pmel.noaa.gov/eoi/rsn/Axial-2017-OOI-zoom-ed-sm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Information Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = 'OOIAPI-J97520T1AYPUNI'\n",
    "TOKEN =  'TEMP-TOKEN-YD01XSNDIO57MP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "from matplotlib import pyplot\n",
    "from pylab import rcParams\n",
    "import pickle as pk\n",
    "import gc\n",
    "import requests \n",
    "import matplotlib.gridspec as gridspec\n",
    "import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For mad help with Pandas https://chrisalbon.com\n",
    "#### For all sorts of great repos https://github.com/rabernat/research_computing.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Downsampled BOTPT Data - I have made pickle files downsampleing the data to 15s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/jovyan/data/botpt/bottom_pressure15S_F11.pkl', 'rb') as E:\n",
    "    botpt_data = pk.load(E)\n",
    "df_botpt = pd.DataFrame(botpt_data)\n",
    "df_botpt['bottom_pressure'] = df_botpt['bottom_pressure'].astype(float)\n",
    "df_botpt['depth']=df_botpt['bottom_pressure'].astype(float) * 0.670\n",
    "#MJ03F_cal_depths = [MJ03F_pressure * 0.0670 for MJ03F_pressure in MJ03F_pressure]\n",
    "#list comprehention\n",
    "epoch= [i.timestamp() for i in df_botpt.index.to_pydatetime()]\n",
    "df_botpt['epoch'] = epoch\n",
    "df_botpt= df_botpt.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/jovyan/data/botpt/bottom_pressure15S_E11.pkl', 'rb') as E:\n",
    "    botpt_data = pk.load(E)\n",
    "df_botptE = pd.DataFrame(botpt_data)\n",
    "df_botptE['bottom_pressure'] = df_botptE['bottom_pressure'].astype(float)\n",
    "df_botptE['depth']=df_botptE['bottom_pressure'].astype(float) * 0.670\n",
    "#MJ03F_cal_depths = [MJ03F_pressure * 0.0670 for MJ03F_pressure in MJ03F_pressure]\n",
    "#list comprehention\n",
    "epoch= [i.timestamp() for i in df_botptE.index.to_pydatetime()]\n",
    "df_botptE['epoch'] = epoch\n",
    "df_botptE= df_botptE.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic Commands \n",
    "# len(df_botpt)\n",
    "# len(df_botptE)\n",
    "# df_botpt.tail()\n",
    "# df_botptE.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning up the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_botptE['epoch']\n",
    "del df_botptE['bottom_pressure']\n",
    "del df_botpt['epoch']\n",
    "del df_botpt['bottom_pressure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df_botptE.head()\n",
    "# y = df_botpt.head()\n",
    "# z = pd.merge(x,y,how='outer', indicator=True, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge BOTPT E and BOTPT F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(df_botpt, df_botptE,how='outer', indicator=True, left_index=True, right_index=True, suffixes=('_F', '_E'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_botptMerge = test[test['_merge'] == 'both']\n",
    "del df_botptMerge['_merge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_botptMerge = df_botptMerge.loc['2017-01-1 00:00:00':'2018-10-31 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_botpt[df_botpt['_merge'] == 'right_only']\n",
    "\n",
    "# df_botpt[df_botpt['_merge'] == 'left_only']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Depth difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthDiff = df_botptMerge['depth_E'].values - df_botptMerge['depth_F'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_botptMerge['diff'] = depthDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h2 = df_botptMerge['depth_F'].tolist()\n",
    "# h1 = df_botptMerge['depth_E'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def subtract_lists(h1, h2):\n",
    "#     diff = [a - b for a,b in zip(h1, h2)]\n",
    "#     return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# height = subtract_lists(h1,h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = list(df_botptMerge.index.values)\n",
    "#height = x.tolist()\n",
    "height = df_botptMerge['diff'].tolist()\n",
    "time_int = []\n",
    "time = list(pd.to_datetime(df_botptMerge.index.values))\n",
    "for i in time:\n",
    "    i = np.datetime64(i).astype(datetime.datetime)\n",
    "    time_int.append(dates.date2num(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(28, 6)\n",
    "hb1 = ax.hexbin(time_int, height, vmin=0, vmax=30, gridsize=(1500,100), mincnt=1, cmap='Greens', linewidths=0)\n",
    "fig.colorbar(hb1, pad = 0.01)\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "ax.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 31, 0, 0))\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(monthsFmt)\n",
    "ax.xaxis.set_minor_locator(years)\n",
    "ax.xaxis.set_minor_formatter(yearsFmt)\n",
    "plt.tight_layout()\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "#plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This method appears to do a pretty good of eliminating the tidal signal. You can clearly see the periods of deflation near 9/2016, 2/2017, 1/2018, and 7/2018\n",
    "\n",
    "##### There is more work to do to eliminate the dropouts and calculate the differing rates of inflation or deflation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('Figures/2015thruPresent.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_botptMerge['date']=pd.DatetimeIndex(df_botptMerge.index).date\n",
    "df_botptMerge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_botptMean=df_botptMerge.groupby('date').mean()\n",
    "df_botptMean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = list(df_botptMerge.index.values)\n",
    "#height = x.tolist()\n",
    "height = df_botptMean['diff'].tolist()\n",
    "time_int = []\n",
    "time = list(pd.to_datetime(df_botptMean.index.values))\n",
    "for i in time:\n",
    "    i = np.datetime64(i).astype(datetime.datetime)\n",
    "    time_int.append(dates.date2num(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(28, 6)\n",
    "hb1 = ax.plot(time_int, height)\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "ax.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 31, 0, 0))\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(monthsFmt)\n",
    "ax.xaxis.set_minor_locator(years)\n",
    "ax.xaxis.set_minor_formatter(yearsFmt)\n",
    "plt.tight_layout()\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "#plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Spikes \n",
    "These drop outs come from slight mismatches between the stations. To remove them I have identified the spikes and replaced them with an adjacent data point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_data = np.array(height)\n",
    "time_array = np.array(time)\n",
    "\n",
    "cleaner_data = []\n",
    "cleaner_time = []\n",
    "\n",
    "# i = 0\n",
    "# while i < len(weird_data):\n",
    "#     if (weird_data[i] - weird_data[i-1] > 2\n",
    "\n",
    "length = len(weird_data)\n",
    "\n",
    "i = 0\n",
    "while i < length:\n",
    "    j = i+2\n",
    "    while j < length:\n",
    "        if np.abs(weird_data[i] - weird_data[j]) < .05:\n",
    "            cleaner_data.append(weird_data[j])\n",
    "            cleaner_time.append(time_array[j])\n",
    "            break\n",
    "        else:\n",
    "            j += 1\n",
    "    i = j\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparison between plots with and without spikes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig3, (ax1,ax2) = plt.subplots(2,1)\n",
    "fig3.set_size_inches(28, 6)\n",
    "hb1 = ax1.plot(time_int, height)\n",
    "ax1.yaxis.grid(True)\n",
    "ax1.xaxis.grid(True)\n",
    "ax1.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 31, 0, 0))\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax1.xaxis.set_major_locator(months)\n",
    "ax1.xaxis.set_major_formatter(monthsFmt)\n",
    "ax1.xaxis.set_minor_locator(years)\n",
    "ax1.xaxis.set_minor_formatter(yearsFmt)\n",
    "\n",
    "hb1 = ax2.plot(cleaner_time, cleaner_data)\n",
    "ax2.yaxis.grid(True)\n",
    "ax2.xaxis.grid(True)\n",
    "ax2.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 31, 0, 0))\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax2.xaxis.set_major_locator(months)\n",
    "ax2.xaxis.set_major_formatter(monthsFmt)\n",
    "ax2.xaxis.set_minor_locator(years)\n",
    "ax2.xaxis.set_minor_formatter(yearsFmt)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=90)\n",
    "#plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/23199796/detect-and-exclude-outliers-in-pandas-dataframe\n",
    "\n",
    "https://stackoverflow.com/questions/35829364/fixing-inflexion-point-estimate-using-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('Figures/2018.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Seismic Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seismic_file = '/home/jovyan/data/hypo71_2018.dat'\n",
    "df_seismic_data = pd.read_csv(seismic_file, delim_whitespace=True, dtype=object)\n",
    "df_seismic_data['datetime'] = df_seismic_data['yyyymmdd'] + 'T' + \\\n",
    "            df_seismic_data['HHMM'].str.slice(start=0, stop=2) + ':' + \\\n",
    "            df_seismic_data['HHMM'].str.slice(start=2) \n",
    "df_seismic_data.index = pd.to_datetime(df_seismic_data['datetime'].values)\n",
    "df_seismic_data['datetime'] = pd.to_datetime(df_seismic_data['datetime'].values)\n",
    "df_seismic_data = df_seismic_data.loc['2017-01-1 00:00:00':'2018-10-31 00:00:00']\n",
    "df_seismic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_seismic_data['yyyymmdd']\n",
    "del df_seismic_data['HHMM']\n",
    "del df_seismic_data['SSS.SS']\n",
    "del df_seismic_data['MW']\n",
    "del df_seismic_data['NWR']\n",
    "del df_seismic_data['GAP']\n",
    "del df_seismic_data['DMIN']\n",
    "del df_seismic_data['ERH']\n",
    "del df_seismic_data['ERZ']\n",
    "del df_seismic_data['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seismic_data.datetime.astype(np.int64).values/1e64\n",
    "df_seismic_data['date']=pd.DatetimeIndex(df_seismic_data.datetime).date\n",
    "df_seismic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seismic_data.resample('D', convention='end').asfreq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eqMean=df_seismic_data.groupby('date').count()\n",
    "del df_eqMean['Lat(D']\n",
    "del df_eqMean['M)']\n",
    "del df_eqMean['Lon(D']\n",
    "del df_eqMean['M).1']\n",
    "del df_eqMean['Depth']\n",
    "del df_eqMean['RMS']\n",
    "del df_eqMean['PMom']\n",
    "del df_eqMean['SMom']\n",
    "df_eqMean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df_eqMean['datetime'].tolist()\n",
    "time_int = []\n",
    "time = list(pd.to_datetime(df_eqMean.index.values))\n",
    "for i in time:\n",
    "    i = np.datetime64(i).astype(datetime.datetime)\n",
    "    time_int.append(dates.date2num(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig4, (ax1,ax2) = plt.subplots(2,1)\n",
    "fig4.set_size_inches(28, 6)\n",
    "hb1 = ax1.plot(cleaner_time, cleaner_data)\n",
    "ax1.yaxis.grid(True)\n",
    "ax1.xaxis.grid(True)\n",
    "ax1.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 31, 0, 0))\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax1.xaxis.set_major_locator(months)\n",
    "ax1.xaxis.set_major_formatter(monthsFmt)\n",
    "ax1.xaxis.set_minor_locator(years)\n",
    "ax1.xaxis.set_minor_formatter(yearsFmt)\n",
    "\n",
    "hb1 = ax2.plot(cleaner_time, count)\n",
    "ax2.yaxis.grid(True)\n",
    "ax2.xaxis.grid(True)\n",
    "ax2.set_xlim(datetime.datetime(2017, 1, 1, 0, 0),datetime.datetime(2018, 10, 31, 0, 0))\n",
    "years = dates.YearLocator()\n",
    "months = dates.MonthLocator()\n",
    "yearsFmt = dates.DateFormatter('\\n\\n\\n%Y')\n",
    "monthsFmt = dates.DateFormatter('%b')\n",
    "ax2.xaxis.set_major_locator(months)\n",
    "ax2.xaxis.set_major_formatter(monthsFmt)\n",
    "ax2.xaxis.set_minor_locator(years)\n",
    "ax2.xaxis.set_minor_formatter(yearsFmt)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=90)\n",
    "#plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "#raw data\n",
    "data = depthDiff\n",
    "\n",
    "plt.plot(np.gradient(data), '+')\n",
    "\n",
    "spl = UnivariateSpline(np.arange(len(data)), np.gradient(data), k=5)\n",
    "spl.set_smoothing_factor(1000)\n",
    "plt.plot(spl(np.arange(len(data))), label='Smooth Fct 1e3')\n",
    "spl.set_smoothing_factor(10000)\n",
    "plt.plot(spl(np.arange(len(data))), label='Smooth Fct 1e4')\n",
    "plt.legend(loc='lower left')\n",
    "#plt.set_xlim(datetime.datetime(2017, 11, 1, 0, 0),datetime.datetime(2018, 8, 31, 0, 0))\n",
    "max_idx = np.argmax(spl(np.arange(len(data))))\n",
    "plt.vlines(max_idx, -.25, .25, linewidth=5, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as so\n",
    "F = lambda x: -spl(x)\n",
    "so.fmin(F, 102)\n",
    "Optimization terminated successfully.\n",
    "         Current function value: -3.339112\n",
    "         Iterations: 20\n",
    "         Function evaluations: 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
