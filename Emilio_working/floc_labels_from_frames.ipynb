{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START HERE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_kubernetes import KubeCluster\n",
    "cluster = KubeCluster(n_workers=0)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a list of CamHD files to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbcamhd = pd.read_json('/home/jovyan/rte-camhd/tim/dbcamhd.json', orient=\"records\", lines=True)\n",
    "dbcamhd.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total files: %i\" % len(dbcamhd))\n",
    "print(\"Total frames: %i\" % dbcamhd.frame_count.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = list(dbcamhd.filename[(dbcamhd.deployment == 5) & (dbcamhd.frame_count > 5000) & (dbcamhd.frame_count < 30000)])\n",
    "filenames.sort()\n",
    "filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the frame numbers from each file to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_numbers = [1000, 2000, 3841, 3933, 4052, 4382, 5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These frame numbers correspond to times in the camera system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycamhd as camhd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moov_atom_timeout(filename):\n",
    "    try:\n",
    "        return camhd.get_moov_atom(filename)\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_timeout(filename, frame_number, pix_fmt, moov_atom):\n",
    "    if moov_atom:\n",
    "        try:\n",
    "            return camhd.get_frame(filename, frame_number, pix_fmt, moov_atom)\n",
    "        except:\n",
    "            return np.zeros((1080, 1920), dtype=np.uint16)\n",
    "    else:\n",
    "        return np.zeros((1080, 1920), dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a delayed Dask array of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycamhd as camhd\n",
    "import numpy as np\n",
    "from dask import delayed\n",
    "import dask.array as dsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_frame_list = []\n",
    "for filename in filenames:\n",
    "    delayed_moov_atom = delayed(get_moov_atom_timeout)(filename)         \n",
    "    for frame_number in frame_numbers:\n",
    "        delayed_frame = delayed(get_frame_timeout)(filename, frame_number, 'gray16le', delayed_moov_atom)\n",
    "        delayed_frame_list.append(dsa.from_delayed(delayed_frame, (1080, 1920), np.uint16))\n",
    "delayed_frame_array = dsa.stack(delayed_frame_list)\n",
    "delayed_frame_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(delayed_frame_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show one of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = delayed_frame_array[0].compute()\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "plt.rc('figure', figsize=(11, 11))\n",
    "fig, ax = plt.subplots()\n",
    "im1 = ax.imshow(frame)\n",
    "im1.set_cmap('gray')\n",
    "plt.yticks(np.arange(0,1081,270))\n",
    "plt.xticks(np.arange(0,1921,480))\n",
    "rect = patches.Rectangle((10,10),1024,1024,linewidth=1.5,edgecolor='w',facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the filter that will be used to filter images in the frequency domain\n",
    "To deal with variations in lighting and high-frequency noise, we filter each subimage using a Butterworth bandpass filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butterworth(d1, d2, n):\n",
    "    x = np.arange(-1024/2+0.5,1024/2+1-0.5)\n",
    "    xx, yy = np.meshgrid(x, x)\n",
    "    d = np.sqrt(xx**2+yy**2)\n",
    "    bff = (1 - (1./(1 + (d/d1)**(2*n))))*(1/(1 + (d/d2)**(2*n)))\n",
    "    return bff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = 20 # low cut wavenumber\n",
    "d2 = 400 # high cut wavenumber\n",
    "n = 4\n",
    "bff = butterworth(d1, d2, n)\n",
    "plt.rc('figure', figsize=(6, 6))\n",
    "imgplot = plt.imshow(bff, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the floc proxy function\n",
    "The floc proxy is simply the number of pixels in each filtered subimage that have a value greater than 4000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_filter(frame, d1, d2, n):\n",
    "    if frame.ndim == 3 and frame.shape[0] == 1:\n",
    "        I = np.squeeze(frame[0, 0:1024, 0:1024])\n",
    "    else:\n",
    "        I = frame[0:1024, 0:1024]\n",
    "    bff = butterworth(d1, d2, n)\n",
    "    I_fft = np.fft.fft2(I)\n",
    "    I_fft_shift = np.fft.fftshift(I_fft)\n",
    "    I_fft_shift_filt = I_fft_shift*bff # filter with the Butterworth filter\n",
    "    I_fft_filt = np.fft.ifftshift(I_fft_shift_filt)\n",
    "    I_filt = np.fft.ifft2(I_fft_filt)\n",
    "    return I_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 4000; # this is an arbitrary threshold that seems to work\n",
    "def frame_thresh(frame, d1, d2, n, threshold):\n",
    "    I_filt = frame_filter(frame, d1, d2, n)\n",
    "    I_thresh = np.array(np.absolute(I_filt)>threshold)\n",
    "    return I_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_thresh = frame_thresh(frame, d1, d2, n, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_floc_proxy(frame, d1, d2, n):\n",
    "#     I_filt = frame_filter(frame, d1, d2, n)\n",
    "#     return np.array([(np.absolute(I_filt)>4000).sum()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show example for one frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I_filt = frame_filter(frame, d1, d2, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(6, 6))\n",
    "imgplot = plt.imshow(I_thresh, cmap='gray')\n",
    "plt.title('floc_proxy value = %i' % I_thresh.sum());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show an example of image labeling using a subimageÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_thresh_sub = I_thresh[735:836, 595:696] # arbitrary area with a few floc particles\n",
    "plt.rc('figure', figsize=(6, 6))\n",
    "imgplot = plt.imshow(I_thresh_sub, cmap='gray')\n",
    "plt.title('Subimage of Thresholded Image to Label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "cmap = mpl.colors.ListedColormap(['white', 'blue', 'red', 'green', 'black'])\n",
    "I_labeled = label(I_thresh_sub, connectivity=2)\n",
    "plt.rc('figure', figsize=(6, 6))\n",
    "imgplot = plt.imshow(I_labeled, cmap=cmap)\n",
    "plt.title('Labeled Image');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows us that skimage.measure.label returns an Numpy array with the same dimensions as the input, with each area labeled with an different integer. The background is all zero, blue=1, red=2, green=3, black=4. This gives us a very easy way to count the number of labeled areas, and determine the size of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pixels per Labeled Area\\nblue: %i\\nred: %i\\ngreen: %i\\nblack: %i' % \n",
    "      ((I_labeled==1).sum(), (I_labeled==2).sum(), \n",
    "       (I_labeled==3).sum(),(I_labeled==4).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes a thresholded binary image as input\n",
    "def frame_label_stats(I_thresh):\n",
    "    I_labeled = label(I_thresh)\n",
    "    label_stats = []\n",
    "    for i in range(1, I_labeled.max()+1):\n",
    "        label_stats.append((I_labeled==i).sum())\n",
    "    return label_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_label_stats = []\n",
    "for filename in filenames:\n",
    "    delayed_moov_atom = delayed(get_moov_atom_timeout)(filename)\n",
    "    for frame_number in frame_numbers:\n",
    "        delayed_frame = delayed(get_frame_timeout)(filename, frame_number, 'gray16le', delayed_moov_atom)\n",
    "        delayed_frame_thresh = delayed(frame_thresh)(delayed_frame, d1, d2, n, threshold)\n",
    "        delayed_label_stats.append(delayed(frame_label_stats)(delayed_frame_thresh))\n",
    "delayed_label_stats[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach the distributed client to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "label_stats = compute(*delayed_label_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count floc particles for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nflocs = [len(i) for i in label_stats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(nflocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a timestamp for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, math\n",
    "import matplotlib.dates as dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = [] #(0,)\n",
    "frame_datenum = [] #(20566,)\n",
    "frame_datetime = [] #(20566,)\n",
    "nflocs = [len(i) for i in label_stats] #(0,)\n",
    "frame_numbered = [] #(20566,)\n",
    "\n",
    "dbcamhd = pd.read_json('/home/jovyan/rte-camhd/tim/dbcamhd.json', orient=\"records\", lines=True)\n",
    "for filename in filenames:\n",
    "    timestamp = dbcamhd['timestamp'][dbcamhd.filename == filename].iloc[0] + frame_number/29.97\n",
    "    for frame_number in frame_numbers:\n",
    "        frame_epoch_seconds = dbcamhd['timestamp'][dbcamhd.filename == filename].iloc[0] + frame_number/29.97\n",
    "        frame_datetime.append(datetime.datetime.fromtimestamp(frame_epoch_seconds))\n",
    "        frame_datenum.append(dates.date2num(frame_datetime[-1]))\n",
    "        frame_numbered.append(frame_number)\n",
    "    \n",
    "#         timestamp = timestamp + frame_number/29.97\n",
    "#         dt = datetime.datetime.fromtimestamp(timestamp)\n",
    "#         frame_timestamp.append(dates.date2num(dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(nflocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = []\n",
    "# frame_timestamp = []\n",
    "# frame_datetime = []\n",
    "# nfloc = []\n",
    "# frame_numbers = []\n",
    "\n",
    "# dbcamhd = pd.read_json('/home/jovyan/rte-camhd/tim/dbcamhd.json', orient=\"records\", lines=True)\n",
    "# for i, row in scene_windows[scene_windows.deployment == 5].iterrows():\n",
    "#     for frame_number in row.frame_list:\n",
    "#         url.append(row.url)\n",
    "#         frame_epoch_seconds = dbcamhd['timestamp'][dbcamhd.filename == row.url].iloc[0] + frame_number/29.97\n",
    "#         frame_datetime.append(datetime.datetime.fromtimestamp(frame_epoch_seconds))\n",
    "#         frame_datenum.append(dates.date2num(frame_datetime[-1]))\n",
    "#         frame_numbers.append(frame_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nflocs = [len(i) for i in label_stats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_results = pd.DataFrame({'frame_number': frame_numbered, 'timestamp': frame_datenum,\n",
    "                        'datetime': frame_datetime, 'nflocs': nflocs, 'label_stats': label_stats})\n",
    "#results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set index as datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_results.set_index('datetime', inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.set_index('Time', inplace =True)\n",
    "#DATAFRAME WITH RESULTS AND A DIFF df WITH DATETIME INDEX, MERGE AND CONVERT TO WHAT i NEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_results.to_csv('frames_resultsfor_Dep4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamps_floc_for_Dep5_floc_proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamps_floc_for_Dep5_floc_proxy = pd.DataFrame(\n",
    "#     {'timestamps': frame_timestamp, 'floc_volume': nflocs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamps_floc_for_Dep5_floc_proxy.to_json('timestamps_floc_for_Dep5_floc_proxy.json', orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a two-dimensional multivariate histogram of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=11)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18, 6)\n",
    "fig.frameon = False\n",
    "hb1 = ax.hexbin(datetime, nflocs, vmin=0, vmax=1.75, bins='log', linewidths=0.1,\n",
    "#   gridsize=(80,100), mincnt=1, cmap=plt.cm.BuPu)\n",
    "fig.colorbar(hb1)\n",
    "ax.set_ylim([0, 1000])\n",
    "ax.set_xlim([frame_timestamp[0],frame_timestamp[-1]])\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "months = dates.MonthLocator()  # every month\n",
    "monthsFmt = dates.DateFormatter('%b %Y')\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(monthsFmt)\n",
    "plt.ylabel('Number of Floc Particles');\n",
    "plt.savefig('Number_of_Floc_Particles_for_Dep5_floc_proxy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assemble a new Dask array including our computation using map_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floc_proxy = dsa.map_blocks(calc_floc_proxy, delayed_frame_array, d1, d2, n, dtype='i8', drop_axis=[1,2])\n",
    "floc_proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the floc_proxy (subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = floc_proxy[0:40].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of images: %i' % len(floc_proxy))\n",
    "print('Size of dataset (GB): %i' % round(len(floc_proxy)*1080*1920*2/1024/1024/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = floc_proxy.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a timestamp for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, math\n",
    "import matplotlib.dates as dates\n",
    "frame_timestamp = []\n",
    "for filename in filenames:\n",
    "    timestamp = dbcamhd['timestamp'][dbcamhd.filename == filename].iloc[0]\n",
    "    for frame_number in frame_numbers:\n",
    "        timestamp = timestamp + frame_number/29.97\n",
    "        dt = datetime.datetime.fromtimestamp(timestamp)\n",
    "        frame_timestamp.append(dates.date2num(dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a two-dimensional multivariate histogram of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=11)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(14, 6)\n",
    "fig.frameon = False\n",
    "hb1 = ax.hexbin(frame_timestamp, results, vmin=0, vmax=1, bins='log', linewidths=0.25,\n",
    "  gridsize=(225,4500), mincnt=1, cmap=plt.cm.BuPu)\n",
    "fig.colorbar(hb1)\n",
    "ax.set_ylim([0, 8000])\n",
    "ax.set_xlim([frame_timestamp[0],frame_timestamp[-1]])\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "months = dates.MonthLocator()  # every month\n",
    "monthsFmt = dates.DateFormatter('%b %Y')\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(monthsFmt)\n",
    "plt.ylabel('Floc Proxy Value');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting in mid-June a large \"floc event\" occurs where the floc proxy values increase on average by about a factor of ten. The cause of this floc event is being investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    " - [Pangeo](http://pangeo-data.org/)\n",
    " - [PyCamHD](https://github.com/tjcrone/pycamhd)\n",
    " - [CamHD Raw Data Archive](https://rawdata.oceanobservatories.org/files/RS03ASHS/PN03B/06-CAMHDA301)\n",
    " - [AGU Abstract](https://agu.confex.com/agu/fm16/meetingapp.cgi/Paper/192670)\n",
    " - [AGU Poster](https://drive.google.com/open?id=0B-dWW4GM434obGpTM0FZME10Nkk)\n",
    " - [Dask](http://dask.pydata.org/en/latest/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
