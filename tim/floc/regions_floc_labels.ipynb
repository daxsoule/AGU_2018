{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seafloor Bacterial Floc Blob Analysis\n",
    "\n",
    "This notebook shows an example of doing an analysis of water column \"floc\" using Pangeo and the regions data from Aaron's [CamHD_motion_metadata](https://github.com/CamHD-Analysis/CamHD_motion_metadata) repo. In this version we use information from blob size and number using connencted components analysis. The goal of this work is to understand changes in the concentration of floc, which is bacterial material that has been flushed from the hydrothermal system into the ocean. Changes in floc are a potential indicator of changes in the hydrothermal system, possibly resulting from a magmatic event or seismic swarm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start a Dask cluster\n",
    "We do this first because it can take a while for the Kubernetes cluster to scale up to accomodate workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_kubernetes import KubeCluster\n",
    "cluster = KubeCluster(n_workers=15)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a list of CamHD files to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = []\n",
    "filename = []\n",
    "scene_tag = []\n",
    "deployment = []\n",
    "start_frame = []\n",
    "end_frame = []\n",
    "\n",
    "with open('region_list.txt') as f:\n",
    "    for line in f:\n",
    "        with open(line.strip()) as l:\n",
    "            data = json.load(l)\n",
    "            for region in data['regions']:\n",
    "                if region['type'] == 'static':\n",
    "                    try:\n",
    "                        if '_p2_z0' in region['sceneTag']:\n",
    "                            url.append('https://rawdata.oceanobservatories.org/files' + data['movie']['URL'])\n",
    "                            filename.append((data['movie']['URL'].split('/')[-1]))\n",
    "                            scene_tag.append(region['sceneTag'])\n",
    "                            deployment.append(int(scene_tag[-1].split('_')[0][1]))                            \n",
    "                            start_frame.append(int(region['startFrame']))\n",
    "                            end_frame.append(int(region['endFrame']))\n",
    "                    except:\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_windows = pd.DataFrame({'filename': filename, 'url': url, 'scene_tag': scene_tag, 'deployment': deployment, 'start_frame': start_frame, 'end_frame': end_frame})\n",
    "scene_windows.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list of frames to process for each scene window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_interval = 10\n",
    "window_buffer = 10\n",
    "frame_lists = []\n",
    "for i, start_frame in enumerate(scene_windows.start_frame):\n",
    "    frame_lists.append(list(range(start_frame+window_buffer, scene_windows.end_frame[i]-window_buffer, frame_interval)))\n",
    "scene_windows['frame_list'] = frame_lists\n",
    "scene_windows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrappers to deal with potential get_moov_atom and get_frame timeouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycamhd as camhd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moov_atom_timeout(filename):\n",
    "    try:\n",
    "        return camhd.get_moov_atom(filename)\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_timeout(filename, frame_number, pix_fmt, moov_atom):\n",
    "    if moov_atom:\n",
    "        try:\n",
    "            return camhd.get_frame(filename, frame_number, pix_fmt, moov_atom)\n",
    "        except:\n",
    "            return np.zeros((1080, 1920), dtype=np.uint16)\n",
    "    else:\n",
    "        return np.zeros((1080, 1920), dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a Dask array of delayed images\n",
    "In this notebook we don't actually use this Dask array of delayed objects for the analysis. Below we refactor into using a list of delayed functions which I think works better here. Or at least it is easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "import dask.array as dsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_frame_list = []\n",
    "for i, row in scene_windows[scene_windows.deployment == 4].iterrows():\n",
    "    filename = row.url\n",
    "    delayed_moov_atom = delayed(get_moov_atom_timeout)(filename)\n",
    "    for frame_number in row.frame_list:\n",
    "        delayed_frame = delayed(get_frame_timeout)(filename, frame_number, 'gray16le', delayed_moov_atom)\n",
    "        delayed_frame_list.append(dsa.from_delayed(delayed_frame, (1080, 1920), np.uint16))\n",
    "delayed_frame_array = dsa.stack(delayed_frame_list)\n",
    "delayed_frame_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dask array is in many ways like a numpy array, except in this case it holds a set of instructions for how to acquire each chunk of the array, which makes it easy to farm this array out to workers in the cloud using the [distributed](http://distributed.readthedocs.io/en/latest/#) scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show one of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = delayed_frame_array[0].compute()\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "plt.rc('figure', figsize=(11, 11))\n",
    "fig, ax = plt.subplots()\n",
    "im1 = ax.imshow(frame)\n",
    "im1.set_cmap('gray')\n",
    "plt.yticks(np.arange(0,1081,270))\n",
    "plt.xticks(np.arange(0,1921,480))\n",
    "rect = patches.Rectangle((10,10),1024,1024,linewidth=1.5,edgecolor='w',facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the filter that will be used to filter images in the frequency domain\n",
    "To deal with variations in lighting and high-frequency noise, we filter each subimage using a Butterworth bandpass filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butterworth(d1, d2, n):\n",
    "    x = np.arange(-1024/2+0.5,1024/2+1-0.5)\n",
    "    xx, yy = np.meshgrid(x, x)\n",
    "    d = np.sqrt(xx**2+yy**2)\n",
    "    bff = (1 - (1./(1 + (d/d1)**(2*n))))*(1/(1 + (d/d2)**(2*n)))\n",
    "    return bff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = 20 # low cut wavenumber\n",
    "d2 = 400 # high cut wavenumber\n",
    "n = 4\n",
    "bff = butterworth(d1, d2, n)\n",
    "plt.rc('figure', figsize=(6, 6))\n",
    "imgplot = plt.imshow(bff, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup filtering and thresholding functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_filter(frame, d1, d2, n):\n",
    "    if frame.ndim == 3 and frame.shape[0] == 1:\n",
    "        I = np.squeeze(frame[0, 0:1024, 0:1024])\n",
    "    else:\n",
    "        I = frame[0:1024, 0:1024]\n",
    "    bff = butterworth(d1, d2, n)\n",
    "    I_fft = np.fft.fft2(I)\n",
    "    I_fft_shift = np.fft.fftshift(I_fft)\n",
    "    I_fft_shift_filt = I_fft_shift*bff # filter with the Butterworth filter\n",
    "    I_fft_filt = np.fft.ifftshift(I_fft_shift_filt)\n",
    "    I_filt = np.fft.ifft2(I_fft_filt)\n",
    "    return I_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 4000; # this is an arbitrary threshold that seems to work\n",
    "def frame_thresh(frame, d1, d2, n, threshold):\n",
    "    I_filt = frame_filter(frame, d1, d2, n)\n",
    "    I_thresh = np.array(np.absolute(I_filt)>threshold)\n",
    "    return I_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show example of a thresholded subimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_thresh = frame_thresh(frame, d1, d2, n, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(6, 6))\n",
    "imgplot = plt.imshow(I_thresh, cmap='gray')\n",
    "plt.title('floc_proxy value = %i' % I_thresh.sum());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show an example of image labeling using a subimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_thresh_sub = I_thresh[735:836, 595:696] # arbitrary area with a few floc particles\n",
    "plt.rc('figure', figsize=(6, 6))\n",
    "imgplot = plt.imshow(I_thresh_sub, cmap='gray')\n",
    "plt.title('Subimage of Thresholded Image to Label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "cmap = mpl.colors.ListedColormap(['white', 'blue', 'red', 'green', 'black'])\n",
    "I_labeled = label(I_thresh_sub, connectivity=2)\n",
    "plt.rc('figure', figsize=(6, 6))\n",
    "imgplot = plt.imshow(I_labeled, cmap=cmap)\n",
    "plt.title('Labeled Image');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows us that skimage.measure.label returns an Numpy array with the same dimensions as the input, with each area labeled with an different integer. The background is all zero, blue=1, red=2, green=3, black=4. This gives us a very easy way to count the number of labeled areas, and determine the size of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pixels per Labeled Area\\nblue: %i\\nred: %i\\ngreen: %i\\nblack: %i' % \n",
    "      ((I_labeled==1).sum(), (I_labeled==2).sum(), \n",
    "       (I_labeled==3).sum(),(I_labeled==4).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup labeling stats function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes a thresholded binary image as input\n",
    "def frame_label_stats(I_thresh):\n",
    "    I_labeled = label(I_thresh)\n",
    "    label_stats = []\n",
    "    for i in range(1, I_labeled.max()+1):\n",
    "        label_stats.append((I_labeled==i).sum())\n",
    "    return label_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assemble a list of Dask delayed functions using our labeling function\n",
    "Here we abandon the delayed Dask array because I am still not sure of what it buys us. It might be worth returning to, but we will use a simple list of nested delayed objects for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_label_stats = []\n",
    "for i, row in scene_windows[scene_windows.deployment == 4].iterrows():\n",
    "    filename = row.url\n",
    "    delayed_moov_atom = delayed(get_moov_atom_timeout)(filename)\n",
    "    for frame_number in row.frame_list:\n",
    "        delayed_frame = delayed(get_frame_timeout)(filename, frame_number, 'gray16le', delayed_moov_atom)\n",
    "        delayed_frame_thresh = delayed(frame_thresh)(delayed_frame, d1, d2, n, threshold)\n",
    "        delayed_label_stats.append(delayed(frame_label_stats)(delayed_frame_thresh))\n",
    "delayed_label_stats[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attach the distributed client to the cluster\n",
    "Make sure all of the workers are ready to go before attaching and running compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate label stats for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "label_stats = compute(*delayed_label_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count floc particles for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nflocs = [len(i) for i in label_stats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nflocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a timestamp for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, math\n",
    "import matplotlib.dates as dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new code warning! datetime index is what we are doing!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = []\n",
    "frame_datenum = []\n",
    "frame_datetime = []\n",
    "# nflocs = [len(i) for i in label_stats]\n",
    "frame_numbers = []\n",
    "\n",
    "dbcamhd = pd.read_json('/home/jovyan/rte-camhd/tim/dbcamhd.json', orient=\"records\", lines=True)\n",
    "for i, row in scene_windows[scene_windows.deployment == 4].iterrows():\n",
    "    for frame_number in row.frame_list:\n",
    "        url.append(row.url)\n",
    "        frame_epoch_seconds = dbcamhd['timestamp'][dbcamhd.filename == row.url].iloc[0] + frame_number/29.97\n",
    "        frame_datetime.append(datetime.datetime.fromtimestamp(frame_epoch_seconds))\n",
    "        frame_datenum.append(dates.date2num(frame_datetime[-1]))\n",
    "        frame_numbers.append(frame_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbcamhd = pd.read_json('/home/jovyan/rte-camhd/tim/dbcamhd.json', orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbcamhd.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_results.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.set_index('Time', inplace =True)\n",
    "#DATAFRAME WITH RESULTS AND A DIFF df WITH DATETIME INDEX, MERGE AND CONVERT TO WHAT i NEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nflocs = [len(i) for i in label_stats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_results = pd.DataFrame({'url': url, 'frame_number': frame_numbers, 'timestamp': frame_datenum,\n",
    "                        'datetime': frame_datetime, 'nflocs': nflocs, 'label_stats': label_stats})\n",
    "# results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_results.to_json('regions_results_for_Dep4.json', orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbcamhd = pd.read_json('/home/jovyan/rte-camhd/tim/dbcamhd.json', orient=\"records\", lines=True)\n",
    "# frame_timestamp = []\n",
    "# for i, row in scene_windows[scene_windows.deployment == 5].iterrows():\n",
    "# #     filename = row.url\n",
    "#     for frame_number in row.frame_list:\n",
    "#         url.append(row.url)\n",
    "#         frame_epoch_seconds = dbcamhd['timestamp'][dbcamhd.filename == row.url].iloc[0] + frame_number/29.97\n",
    "#         frame_datetime.append(datetime.datetime.fromtimestamp(frame_epoch_seconds))\n",
    "#         frame_num.append(dates.date2num(frame_datetime[-1]))\n",
    "#         frame_numbers.append(frame_number)\n",
    "# #         dt = datetime.datetime.fromtimestamp(timestamp)\n",
    "# #         frame_timestamp.append(dates.date2num(dt))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(nflocs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.DataFrame(['A': [1], 'time'; pd.to_datetime(datetime.datetime.frometimestamp())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_timestamps_floc_for_Dep6_Region = pd.DataFrame(\n",
    "#     {'timestamps': frame_timestamp, 'floc_volume': nflocs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_timestamps_floc_for_Dep6_Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a two-dimensional multivariate histogram of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=11)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18, 6)\n",
    "fig.frameon = False\n",
    "hb1 = ax.hexbin(frame_timestamp, nflocs, vmin=0, vmax=1.75, bins='log', linewidths=0.1,\n",
    "  gridsize=(80,100), mincnt=1, cmap=plt.cm.BuPu)\n",
    "fig.colorbar(hb1)\n",
    "ax.set_ylim([0, 1000])\n",
    "ax.set_xlim([frame_timestamp[0],frame_timestamp[-1]])\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "months = dates.DayLocator()  # every other day\n",
    "monthsFmt = dates.DateFormatter('%d %m')\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(monthsFmt)\n",
    "plt.ylabel('Number of Floc Particles');\n",
    "plt.savefig('Number_of_Floc_Particles.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a two-dimensional multivariate histogram of the results using hvplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.hvplot.hexbin(x='timestamp', y='nflocs', width=800, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_results.hvplot.scatter(x='datetime', y='nflocs', datashade=True, width=720, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    " - [Pangeo](http://pangeo-data.org/)\n",
    " - [PyCamHD](https://github.com/tjcrone/pycamhd)\n",
    " - [CamHD Raw Data Archive](https://rawdata.oceanobservatories.org/files/RS03ASHS/PN03B/06-CAMHDA301)\n",
    " - [AGU Abstract](https://agu.confex.com/agu/fm16/meetingapp.cgi/Paper/192670)\n",
    " - [AGU Poster](https://drive.google.com/open?id=0B-dWW4GM434obGpTM0FZME10Nkk)\n",
    " - [Dask](http://dask.pydata.org/en/latest/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
