{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seafloor Bacterial Floc Analysis Using Regions Information\n",
    "\n",
    "This notebook shows an example of doing an analysis of water column \"floc\" using Pangeo and the regions data from Aaron's [CamHD_motion_metadata](https://github.com/CamHD-Analysis/CamHD_motion_metadata) repo. The goal of this work is to understand changes in the concentration of floc, which is bacterial material that has been flushed from the hydrothermal system into the ocean. Changes in floc are a potential indicator of changes in the hydrothermal system, possibly resulting from a magmatic event or seismic swarm.\n",
    " \n",
    " \n",
    "In this notebook we analyze a large number of OOI HD video camera frames to establish a proxy for the floc concentration, and then display the results using a two-dimensional multivariate histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a list of CamHD files to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = []\n",
    "filename = []\n",
    "scene_tag = []\n",
    "deployment = []\n",
    "start_frame = []\n",
    "end_frame = []\n",
    "\n",
    "with open('region_list.txt') as f:\n",
    "    for line in f:\n",
    "        with open(line.strip()) as l:\n",
    "            data = json.load(l)\n",
    "            for region in data['regions']:\n",
    "                if region['type'] == 'static':\n",
    "                    try:\n",
    "                        if '_p2_z0' in region['sceneTag']:\n",
    "                            url.append('https://rawdata.oceanobservatories.org/files' + data['movie']['URL'])\n",
    "                            filename.append((data['movie']['URL'].split('/')[-1]))\n",
    "                            scene_tag.append(region['sceneTag'])\n",
    "                            deployment.append(int(scene_tag[-1].split('_')[0][1]))                            \n",
    "                            start_frame.append(int(region['startFrame']))\n",
    "                            end_frame.append(int(region['endFrame']))\n",
    "                    except:\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_windows = pd.DataFrame({'filename': filename, 'url': url, 'scene_tag': scene_tag, 'deployment': deployment, 'start_frame': start_frame, 'end_frame': end_frame})\n",
    "scene_windows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 30\n",
    "frame_numbers = []\n",
    "for i,start_frame in enumerate(scene_windows.start_frame):\n",
    "    frame_numbers.append(list(range(start_frame, scene_windows.end_frame[i], 30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_numbers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_windows.loc[0].start_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scene_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = list(scene_windows.url[(scene_windows.deployment == 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the frame numbers from each file to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_numbers = list(scene_windows.start_frame[(scene_windows.deployment == 5)]+10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These frame numbers correspond to times when the camera system is looking over the \"shoulder\" of Mushroom vent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a delayed Dask array of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycamhd as camhd\n",
    "import numpy as np\n",
    "from dask import delayed\n",
    "import dask.array as dsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_frame_list = []\n",
    "for i, filename in enumerate(filenames):\n",
    "    delayed_moov_atom = delayed(camhd.get_moov_atom)(filename)\n",
    "    delayed_frame = delayed(camhd.get_frame)(filename, frame_numbers[i], 'gray16le', delayed_moov_atom)\n",
    "    delayed_frame_list.append(dsa.from_delayed(delayed_frame, (1080, 1920), np.uint16))\n",
    "   \n",
    "delayed_frame_array = dsa.stack(delayed_frame_list)\n",
    "delayed_frame_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(delayed_moov_atom.dask.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dask array is in many ways like a numpy array, except in this case it holds a set of instructions for how to acquire each chunk of the array, which makes it easy to farm this array out to workers in the cloud using the [distributed](http://distributed.readthedocs.io/en/latest/#) scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show one of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = delayed_frame_array[0].compute()\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "plt.rc('figure', figsize=(11, 11))\n",
    "fig, ax = plt.subplots()\n",
    "im1 = ax.imshow(frame)\n",
    "im1.set_cmap('gray')\n",
    "plt.yticks(np.arange(0,1081,270))\n",
    "plt.xticks(np.arange(0,1921,480))\n",
    "rect = patches.Rectangle((10,10),1024,1024,linewidth=1.5,edgecolor='w',facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the filter that will be used to filter images in the frequency domain\n",
    "To deal with variations in lighting and high-frequency noise, we filter each subimage using a Butterworth bandpass filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butterworth(d1, d2, n):\n",
    "    x = np.arange(-1024/2+0.5,1024/2+1-0.5)\n",
    "    xx, yy = np.meshgrid(x, x)\n",
    "    d = np.sqrt(xx**2+yy**2)\n",
    "    bff = (1 - (1./(1 + (d/d1)**(2*n))))*(1/(1 + (d/d2)**(2*n)))\n",
    "    return bff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = 20 # low cut wavenumber\n",
    "d2 = 400 # high cut wavenumber\n",
    "n = 4\n",
    "bff = butterworth(d1, d2, n)\n",
    "plt.rc('figure', figsize=(6, 6))\n",
    "imgplot = plt.imshow(bff, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the floc proxy function\n",
    "The floc proxy is simply the number of pixels in each filtered subimage that have a value greater than 4000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_filter(frame, d1, d2, n):\n",
    "    if frame.ndim == 3 and frame.shape[0] == 1:\n",
    "        I = np.squeeze(frame[0, 0:1024, 0:1024])\n",
    "    else:\n",
    "        I = frame[0:1024, 0:1024]\n",
    "    bff = butterworth(d1, d2, n)\n",
    "    I_fft = np.fft.fft2(I)\n",
    "    I_fft_shift = np.fft.fftshift(I_fft)\n",
    "    I_fft_shift_filt = I_fft_shift*bff # filter with the Butterworth filter\n",
    "    I_fft_filt = np.fft.ifftshift(I_fft_shift_filt)\n",
    "    I_filt = np.fft.ifft2(I_fft_filt)\n",
    "    return I_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_floc_proxy(frame, d1, d2, n):\n",
    "    I_filt = frame_filter(frame, d1, d2, n)\n",
    "    return np.array([(np.absolute(I_filt)>4000).sum()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show example for one frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_filt = frame_filter(frame, d1, d2, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(6, 6))\n",
    "imgplot = plt.imshow(np.absolute(I_filt)>4000, cmap='gray')\n",
    "plt.title('floc_proxy value = %i' % (np.absolute(I_filt)>4000).sum());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assemble a new Dask array including our computation using map_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floc_proxy = dsa.map_blocks(calc_floc_proxy, delayed_frame_array, d1, d2, n, dtype='i8', drop_axis=[1,2])\n",
    "floc_proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the floc_proxy (subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = floc_proxy[0:40].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start a Dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_kubernetes import KubeCluster\n",
    "cluster = KubeCluster(n_workers=30)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = floc_proxy[0:400].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of images: %i' % len(floc_proxy))\n",
    "print('Size of dataset (GB): %i' % round(len(floc_proxy)*1080*1920*2/1024/1024/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = floc_proxy.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a timestamp for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbcamhd = pd.read_json('/home/jovyan/rte-camhd/tim/dbcamhd.json', orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, math\n",
    "import matplotlib.dates as dates\n",
    "frame_timestamp = []\n",
    "for i, filename in enumerate(filenames):    \n",
    "    timestamp = dbcamhd['timestamp'][dbcamhd.filename == filename].iloc[0]\n",
    "    timestamp = timestamp + frame_numbers[i]/29.97\n",
    "    dt = datetime.datetime.fromtimestamp(timestamp)\n",
    "    frame_timestamp.append(dates.date2num(dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a two-dimensional multivariate histogram of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=11)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(14, 6)\n",
    "fig.frameon = False\n",
    "hb1 = ax.hexbin(frame_timestamp, results, vmin=0.1, vmax=2, bins='log', linewidths=0.25,\n",
    "  gridsize=(225,4500), mincnt=1, cmap=plt.cm.BuPu)\n",
    "fig.colorbar(hb1)\n",
    "ax.set_ylim([0, 8000])\n",
    "ax.set_xlim([frame_timestamp[0],frame_timestamp[-1]])\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "months = dates.MonthLocator()  # every month\n",
    "monthsFmt = dates.DateFormatter('%b %Y')\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(monthsFmt)\n",
    "plt.ylabel('Floc Proxy Value');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting in mid-June a large \"floc event\" occurs where the floc proxy values increase on average by about a factor of ten. The cause of this floc event is being investigated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    " - [Pangeo](http://pangeo-data.org/)\n",
    " - [PyCamHD](https://github.com/tjcrone/pycamhd)\n",
    " - [CamHD Raw Data Archive](https://rawdata.oceanobservatories.org/files/RS03ASHS/PN03B/06-CAMHDA301)\n",
    " - [AGU Abstract](https://agu.confex.com/agu/fm16/meetingapp.cgi/Paper/192670)\n",
    " - [AGU Poster](https://drive.google.com/open?id=0B-dWW4GM434obGpTM0FZME10Nkk)\n",
    " - [Dask](http://dask.pydata.org/en/latest/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
